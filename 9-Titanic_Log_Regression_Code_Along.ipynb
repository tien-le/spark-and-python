{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Code Along\n",
    "This is a code along of the famous titanic dataset, its always nice to start off with this dataset because it is an example you will find across pretty much every data analysis language.\n",
    "\n",
    "## Sample Data\n",
    "```\n",
    "PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked\n",
    "1,0,3,\"Braund, Mr. Owen Harris\",male,22,1,0,A/5 21171,7.25,,S\n",
    "2,1,1,\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",female,38,1,0,PC 17599,71.2833,C85,C\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B1: Creating SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:20.667554Z",
     "start_time": "2020-02-14T16:16:12.019036Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"logistic_regression_code_along\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B2: Loading input corpus\n",
    "'titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:21.402101Z",
     "start_time": "2020-02-14T16:16:21.391129Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_input_path = \"./../input_data/\"\n",
    "file_input_path = dir_input_path + 'titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:46.130614Z",
     "start_time": "2020-02-14T16:16:46.113660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified Input Path :  ./../input_data/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(file_input_path):\n",
    "    print(\"File Not Found : \", file_input_path)\n",
    "else:\n",
    "    print(\"Verified Input Path : \", file_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:52.843539Z",
     "start_time": "2020-02-14T16:16:47.249472Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(file_input_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B3: Showing overview of input corpus\n",
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:54.213182Z",
     "start_time": "2020-02-14T16:16:54.128409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:57.417992Z",
     "start_time": "2020-02-14T16:16:55.274719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:16:58.666156Z",
     "start_time": "2020-02-14T16:16:58.580386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:00.076459Z",
     "start_time": "2020-02-14T16:16:59.706446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0| PC 17599|71.2833|  C85|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+---------+-------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:07.503805Z",
     "start_time": "2020-02-14T16:17:06.341856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', None], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()[\"Embarked\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:09.129309Z",
     "start_time": "2020-02-14T16:17:08.376322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q', None, 'C', 'S']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_name = \"Embarked\"\n",
    "[i[col_name] for i in df.select(col_name).distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:10.519975Z",
     "start_time": "2020-02-14T16:17:09.881679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Embarked|\n",
      "+--------+\n",
      "|       Q|\n",
      "|    null|\n",
      "|       C|\n",
      "|       S|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_name = \"Embarked\"\n",
    "df.select(col_name).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing each item in the first line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:12.578603Z",
     "start_time": "2020-02-14T16:17:12.335253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "3\n",
      "Braund, Mr. Owen Harris\n",
      "male\n",
      "22.0\n",
      "1\n",
      "0\n",
      "A/5 21171\n",
      "7.25\n",
      "None\n",
      "S\n"
     ]
    }
   ],
   "source": [
    "for item in df.head():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data in columns (in more detail)\n",
    "\n",
    "As you see, we have some categorical features as follows:\n",
    "\n",
    "+ Sex (male, female)\n",
    "+ Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show distinct values in some columns: Sex, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:16.047211Z",
     "start_time": "2020-02-14T16:17:15.474740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|   Sex|\n",
      "+------+\n",
      "|female|\n",
      "|  male|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_name = \"Sex\"\n",
    "df.select(col_name).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:17.482162Z",
     "start_time": "2020-02-14T16:17:16.899696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Embarked|\n",
      "+--------+\n",
      "|       Q|\n",
      "|    null|\n",
      "|       C|\n",
      "|       S|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_name = \"Embarked\"\n",
    "df.select(col_name).distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show row that containing NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:19.670553Z",
     "start_time": "2020-02-14T16:17:19.338465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
      "|         62|       1|     1| Icard, Miss. Amelie|female|38.0|    0|    0|113572|80.0|  B28|    null|\n",
      "|        830|       1|     1|Stone, Mrs. Georg...|female|62.0|    0|    0|113572|80.0|  B28|    null|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_name = \"Embarked\"\n",
    "df.where(df[col_name].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:20.725150Z",
     "start_time": "2020-02-14T16:17:20.508728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_name = \"Embarked\"\n",
    "df.where(df[col_name].isNotNull()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B4: Data Preprocessing\n",
    "\n",
    "## Dealing with the categorical variable\n",
    "+ Using StringIndexer\n",
    "\n",
    "+ Using OneHotEncoderEstimator\n",
    "\n",
    "Example Column: Sex, Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:22.669186Z",
     "start_time": "2020-02-14T16:17:22.434731Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:23.398650Z",
     "start_time": "2020-02-14T16:17:23.378704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:24.413284Z",
     "start_time": "2020-02-14T16:17:24.229801Z"
    }
   },
   "outputs": [],
   "source": [
    "sex_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"sex_indexer\")\n",
    "sex_onehot = OneHotEncoderEstimator(inputCols=[\"sex_indexer\"], outputCols=[\"sex_onehot\"])\n",
    "\n",
    "embarked_indexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"embarked_indexer\")\n",
    "embarked_onehot = OneHotEncoderEstimator(inputCols=[\"embarked_indexer\"], outputCols=[\"embarked_onehot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop NULL line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:28.031907Z",
     "start_time": "2020-02-14T16:17:27.931175Z"
    }
   },
   "outputs": [],
   "source": [
    "df_not_null = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:29.879675Z",
     "start_time": "2020-02-14T16:17:29.585460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name|Sex|Age|SibSp|Parch|Ticket|Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "+-----------+--------+------+----+---+---+-----+-----+------+----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "col_name = \"Embarked\"\n",
    "df_not_null.where(df_not_null[col_name].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B5: Creating VectorAssembler for 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:33.384136Z",
     "start_time": "2020-02-14T16:17:33.284400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_null.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:35.782534Z",
     "start_time": "2020-02-14T16:17:35.587080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|  Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|PC 17599|71.2833|  C85|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+--------+-------+-----+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_not_null.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:37.028511Z",
     "start_time": "2020-02-14T16:17:37.008593Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:38.079981Z",
     "start_time": "2020-02-14T16:17:37.979250Z"
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Pclass', 'sex_onehot', \n",
    "                                       'Age', 'SibSp', \n",
    "                                       'Parch', 'Fare', \n",
    "                                       'embarked_onehot'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B7: Training & Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:44.415345Z",
     "start_time": "2020-02-14T16:17:44.394400Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:45.557265Z",
     "start_time": "2020-02-14T16:17:45.393700Z"
    }
   },
   "outputs": [],
   "source": [
    "lg = LogisticRegression(featuresCol=\"features\", labelCol=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Cach 2) Applying pipeline\n",
    "+ Using Pipeline from pyspark.ml with given stages as follows: StringIndexer, OneHotEncoderEstimator, VectorAssembler, LogisticRegression\n",
    "+ Splitting Full Data to Training set & Testing set\n",
    "    - Fitting pipeline with training set\n",
    "    - Transforming with testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:49.491834Z",
     "start_time": "2020-02-14T16:17:49.472885Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:50.464541Z",
     "start_time": "2020-02-14T16:17:50.445591Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    sex_indexer, embarked_indexer, sex_onehot, embarked_onehot, assembler, lg\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:51.536617Z",
     "start_time": "2020-02-14T16:17:51.388037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting Full Data to Training set & Testing set\n",
    "train_set, test_set = df_not_null.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:56.832408Z",
     "start_time": "2020-02-14T16:17:52.446128Z"
    }
   },
   "outputs": [],
   "source": [
    "## Fitting pipeline with training set\n",
    "lg_model_fit = pipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:58.239476Z",
     "start_time": "2020-02-14T16:17:57.981758Z"
    }
   },
   "outputs": [],
   "source": [
    "## Transforming with testing set\n",
    "test_result = lg_model_fit.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:17:59.053385Z",
     "start_time": "2020-02-14T16:17:59.033438Z"
    }
   },
   "outputs": [],
   "source": [
    "test_summary = test_result.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:18:00.189599Z",
     "start_time": "2020-02-14T16:18:00.168685Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:18:01.388503Z",
     "start_time": "2020-02-14T16:18:01.001056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+-----+-----+--------+-----------+----------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|Ticket| Fare|Cabin|Embarked|sex_indexer|embarked_indexer|   sex_onehot|embarked_onehot|            features|       rawPrediction|         probability|prediction|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+-----+-----+--------+-----------+----------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|113803| 53.1| C123|       S|        0.0|             0.0|(1,[0],[1.0])|  (2,[0],[1.0])|[1.0,1.0,35.0,1.0...|[-3.0880694482562...|[0.04360206986101...|       1.0|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|113783|26.55| C103|       S|        0.0|             0.0|(1,[0],[1.0])|  (2,[0],[1.0])|[1.0,1.0,58.0,0.0...|[-1.6867368521202...|[0.15620545800196...|       1.0|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+------+-----+-----+--------+-----------+----------------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:18:02.415629Z",
     "start_time": "2020-02-14T16:18:02.337837Z"
    }
   },
   "outputs": [],
   "source": [
    "eval = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:18:03.719771Z",
     "start_time": "2020-02-14T16:18:03.356561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|prediction|Survived|\n",
      "+----------+--------+\n",
      "|       1.0|       1|\n",
      "|       1.0|       1|\n",
      "|       0.0|       1|\n",
      "+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_result.select(\"prediction\", \"Survived\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T16:18:05.428232Z",
     "start_time": "2020-02-14T16:18:04.849777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.708403361344538\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC :\", eval.evaluate(test_result))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
